{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Train a Sequence to Sequence Model with Attention on the ROC Story Dataset\n",
        "**Using the ROC Story Dataset of day #3 (lien [ici](https://drive.google.com/file/d/1eJINcSbC3JLl0hTNbhh5G94zTuXinpC-/view?usp=sharing)), build a sequence to sequence model with attention that takes as input sentence the sentence #1 (input of the encoder), and takes as target sentence (input of the decoder), the sentence #2**.   \n",
        "\n",
        "This creates an encoder-decoder model for story continuation.\n",
        "For the model, you can use either: \n",
        "1. The Seq2Seq RNN Model with attention of [notebook of day #4](https://colab.research.google.com/drive/1GPnhw6iQzVSMPvr8-dU8n3gJD67b9Upr?usp=sharing)\n",
        "> You can tweak the model, for example using a Multiplicative Attention instead of an Additive Attention\n",
        "2. A Transformer model. There is a great tutorial and transformer implementation in tensorflow here: https://www.tensorflow.org/text/tutorials/transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.41.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: clang~=5.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras~=2.6 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
            "You should consider upgrading via the '/Users/mohamedaminechafik/opt/anaconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: transformers in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (4.16.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
            "Requirement already satisfied: filelock in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
            "Requirement already satisfied: six in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /Users/mohamedaminechafik/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
            "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
            "You should consider upgrading via the '/Users/mohamedaminechafik/opt/anaconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install transformers\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d6c6XcztZHLg"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b2f41bb14b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/mohamedaminechafik/Downloads/ROCStories_winter2017.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sentence2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "data = pd.read_csv(\"/Users/mohamedaminechafik/Downloads/ROCStories_winter2017.csv\")\n",
        "data_train, data_test= train_test_split(data[['sentence1',\"sentence2\"]], test_size=0.2, random_state=1)\n",
        "data.sentence1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import datasets\n",
        "\n",
        "train_dataset = Dataset.from_pandas(data_train)\n",
        "test_dataset = Dataset.from_pandas(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = datasets.DatasetDict({\"train\":train_dataset,\"test\":test_dataset})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's create a Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "import torch\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
        "model = GPT2Model.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "\n",
        "outputs = model(**inputs)\n",
        "\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentence1': Value(dtype='string', id=None),\n",
              " 'sentence2': Value(dtype='string', id=None),\n",
              " '__index_level_0__': Value(dtype='int64', id=None)}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
        "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Assigning [PAD] to the pad_token key of the tokenizer\n"
          ]
        }
      ],
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "tokenized_dataset = tokenizer(\n",
        "    dataset[\"train\"][\"sentence1\"],\n",
        "    dataset[\"train\"][\"sentence2\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', '__index_level_0__'],\n",
              "        num_rows: 42132\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', '__index_level_0__'],\n",
              "        num_rows: 10533\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:06<00:00,  6.49ba/s]\n",
            "100%|██████████| 11/11 [00:01<00:00, 10.09ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 42132\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 10533\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[27, 32, 25, 24, 14, 14, 24, 13]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "\n",
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "metric = load_metric(\"glue\", \"mrpc\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = load_metric(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['attention_mask', 'input_ids', 'labels', 'token_type_ids']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#progress bar \n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation loop:\n",
        "\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"glue\", \"mrpc\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers, what can they do?",
      "provenance": []
    },
    "interpreter": {
      "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
